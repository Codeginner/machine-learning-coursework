{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Codeginner/machineLearning-task/blob/main/UAS/PyTorch/Chapter%2000/Code_Chapter_00_pytorch_fundamentals.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nama: Gilman Muslih Z\n",
        "\n",
        "NIM: 1103201075\n",
        "\n",
        "Codes Chapter 00 - Fundamental"
      ],
      "metadata": {
        "id": "6hJmr6GO8Rlw"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5v3iRCRUTGeu"
      },
      "source": [
        "## Import PyTorch\n",
        "\n",
        "> Sebelum menggunakan framework PyTorch ke dalam project yang ingin kita buat, pertama yang harus dilakukan adalah meng-import library PyTorch serta mengecek versi PyTorch yang digunakan\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "1VxEOik46Y4i",
        "outputId": "14f5dbd8-f67b-4d85-e8ae-cbd76031d938"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.1.0+cu121'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import torch\n",
        "torch.__version__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_SqvI4S9TGew"
      },
      "source": [
        "Library PyTorch berhasil di-import dan seperti yang dilihat pada output kode di atas, versi PyTorch yang digunakan adalah 2.1.0+cu121 di mana pada petunjuk yang terdapat pada modul PyTorch ini dikatakan ketika versi PyTorch yang digunakan lebih besar dari 1.10.0+ akan terdapat beberapa perbedaan."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFF0N2TU7S7Q"
      },
      "source": [
        "### Membuat tensor\n",
        "\n",
        "> Untuk membuat tensor, pertama yang harus diketahui adalah scalar. Membuat scalar dapat memberikan fleksibilitas dalam mengelola data di PyTorch. Tensor skalar merupakan dasar untuk membangun struktur data yang lebih kompleks seperti vektor, matriks, dan tensor multidimensi lainnya."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YUDgG2zk7Us5",
        "outputId": "88f0664d-445b-4637-aa18-144ba82a733e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(7)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "# Scalar\n",
        "scalar = torch.tensor(7)\n",
        "scalar"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JqSuhW7rTGey"
      },
      "source": [
        "Dengan output yang dihasilkan, kita telah berhasil membuat tensor skalar dengan nilai 7 menggunakan PyTorch. Output tensor(7) menandakan meskipun scalar adalah sebuah angka tunggal, scalar merupakan tipe torch.Tensor. Kita bisa memeriksa dimensi dari sebuah tensor menggunakan atribut `ndim`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lV98Yz868bav",
        "outputId": "0c1a0dd2-8b1f-4996-cd90-42c9072cd707"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "scalar.ndim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZO2YW_QGTGez"
      },
      "source": [
        "0 memberikan informasi tentang seberapa banyak dimensi yang dimiliki oleh tensor, dan dalam konteks tensor skalar, dimensinya adalah 0 karena hanya ada satu elemen tanpa dimensi tambahan.\n",
        "\n",
        "Bagaimana jika kita ingin mengambil angka dari tensor. Misalnya, mengubahnya dari torch.Tensor menjadi bilangan bulat Python.\n",
        "\n",
        "Untuk melakukannya kita dapat menggunakan metode item()."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-k4cyKumPfbE",
        "outputId": "66a9a195-cdc8-44f6-c0b5-cb9a539969dd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# Dapatkan angka Python dalam sebuah tensor (hanya bekerja dengan tensor satu elemen)\n",
        "scalar.item()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dalam kode tersebut, `scalar.item()` digunakan untuk mengambil nilai skalar yang terkandung dalam tensor. Karena tensor skalar hanya memiliki satu elemen, panggilan fungsi `item()` mengembalikan nilai aktual dari tensor tersebut. Dalam hal ini, nilai dari tensor skalar yang telah dibuat sebelumnya adalah 7, sehingga output dari `scalar.item()` adalah 7. Fungsi ini berguna ketika kita perlu mengakses nilai dari tensor skalar secara langsung sebagai bilangan Python biasa, bukan sebagai objek tensor PyTorch."
      ],
      "metadata": {
        "id": "_e3xauD8M-lN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vector merupakan tensor 1 dimensi akan tetapi dapat menyimpan banyak angka. Misalnya, Anda dapat memiliki vektor [3, 2] untuk mendeskripsikan [kamar tidur, kamar mandi] di rumah Anda. Atau Anda dapat memiliki [3, 2, 2] untuk mendeskripsikan [kamar tidur, kamar mandi, tempat parkir mobil] di rumah Anda. Hal yang penting di sini adalah bahwa vektor bersifat fleksibel dalam merepresentasikan apa yang dapat direpresentasikannya (sama halnya dengan tensor)."
      ],
      "metadata": {
        "id": "joKcxbavN7JX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-IZF6ASs8QH9",
        "outputId": "b4ab7a45-3ace-462e-953d-8d6a3ca576da"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([7, 7])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# Vector\n",
        "vector = torch.tensor([7, 7])\n",
        "vector"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Baris pertama, `vector = torch.tensor([7, 7])`, membuat sebuah tensor vektor dengan dua elemen, yaitu 7 dan 7. Vektor ini dapat dianggap sebagai larik satu dimensi atau himpunan nilai yang disusun dalam urutan tertentu."
      ],
      "metadata": {
        "id": "Tx1CYgRINQZ2"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mXxRUUW2TGe1"
      },
      "source": [
        "Selanjutnya, memeriksa dimensi dari vektor yang telah dibuat sebelumnya"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03hm3VVv8kr4",
        "outputId": "505fbf47-1254-44f0-919b-523997791c56"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# cek dimensi dari vektor yang telah dibuat sebelumnya\n",
        "vector.ndim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0VYvSGbTGe1"
      },
      "source": [
        "Dari output di atas, vektor berisi dua angka tetapi hanya memiliki satu dimensi. Kita dapat mengetahui jumlah dimensi yang dimiliki tensor di PyTorch dari jumlah tanda kurung siku di bagian luar ([) dan hanya perlu menghitung satu sisi saja.\n",
        "\n",
        "Berapa banyak tanda kurung siku yang dimiliki vektor?\n",
        "\n",
        "Konsep penting lainnya untuk tensor adalah atribut bentuknya. Bentuknya dapat memberi tahu bagaimana elemen-elemen di dalamnya disusun.\n",
        "\n",
        "\n",
        "Untuk mengetahui bentuk vektor, dapat menggunakan kode di bawah ini"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6zREV1bDTGe2",
        "outputId": "aeae1f9c-b49c-42de-957a-3e3f712c1ff6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# cek bentuk vektor\n",
        "vector.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9aWKppNyTGe2"
      },
      "source": [
        "Kode di atas menghasilkan `torch.Size([2])` yang berarti vektor kita memiliki bentuk `[2]`. Hal ini dikarenakan dua elemen yang kita tempatkan di dalam kurung siku (`[7, 7]`).\n",
        "\n",
        "Selanjutnya **matrix**."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Matriks sering digunakan dalam berbagai aplikasi, termasuk transformasi linear, image processing, dan pemodelan sistem linier dalam konteks data science dan machine learning. Dengan menggunakan PyTorch, kita dapat dengan mudah membuat, memanipulasi, dan melakukan operasi matematis pada matriks-matriks ini."
      ],
      "metadata": {
        "id": "pcPZXreVQHca"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D5iNwCYL8QO9",
        "outputId": "ac511c48-82c4-494a-819a-d50a23f24157"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 7,  8],\n",
              "        [ 9, 10]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# membuat Matrix\n",
        "MATRIX = torch.tensor([[7, 8],\n",
        "                       [9, 10]])\n",
        "MATRIX"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a3U1bCdjTGe3"
      },
      "source": [
        "matriks memberikan fleksibilitas yang sama seperti vektor, tetapi dengan dimensi tambahan yang memungkinkan representasi data yang lebih kompleks."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Selanjutnya mengecek dimensi dari matriks yang telah dibuat sebelumnya"
      ],
      "metadata": {
        "id": "jIHDNVTtQl27"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8LREUbeb8r8j",
        "outputId": "f1a87e56-6605-4719-c024-e65112479d87"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# memeriksa dimensi dari MATRIX\n",
        "MATRIX.ndim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LhXXgq-dTGe3"
      },
      "source": [
        "Output di atas menampilkan bahwa `MATRIX` memiliki 2 dimensi sedangkan kalau kita mengecek bentuk dari `MATRIX` itu sendiri?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_TL26I31TGe3",
        "outputId": "4c06db19-aaea-43a0-e27e-cb5c595728e3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# cek bentuk dari MATRIX\n",
        "MATRIX.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dvLpUvrKTGe4"
      },
      "source": [
        "Output yang didapatkan adalah `torch.Size([2, 2])` karena matriks yang telah dibuat sebelumnya memiliki kedalaman dua elemen dan lebar dua elemen.\n",
        "\n",
        "\"dimension\" atau \"dimensi\" merujuk pada jumlah sumbu atau tingkat struktur dalam tensor, sementara \"shape\" atau \"bentuk\" memberikan informasi tentang seberapa banyak elemen yang terdapat dalam setiap dimensi.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Selanjutnya membuat **tensor**"
      ],
      "metadata": {
        "id": "cK2ZOBfcReu4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wEMDQr188QWW",
        "outputId": "cc1326a3-fc0c-4cb4-ae18-bc6263492439"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[1, 2, 3],\n",
              "         [3, 6, 9],\n",
              "         [2, 4, 5]]])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# membuat Tensor\n",
        "TENSOR = torch.tensor([[[1, 2, 3],\n",
        "                        [3, 6, 9],\n",
        "                        [2, 4, 5]]])\n",
        "TENSOR"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kode di atas menciptakan sebuah tensor dengan tiga dimensi, di mana terdapat tiga tingkat struktur data. Tensor ini dapat dianggap sebagai kumpulan matriks, di mana setiap matriks 3x3 ditempatkan di dalam tensor induk.\n",
        "\n",
        "Dapat dilihat, Tensor ini terdiri dari beberapa matriks. Untuk mengetahui ukurannya, kita dapat memeriksa dimensi dan bentuk (shape) dari Tensor yang telah kita buat sebelumnya"
      ],
      "metadata": {
        "id": "fZ5EQvp8So_a"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8dhuEsjS8QcT",
        "outputId": "66025aaa-eb00-4f2b-9838-160f694f7154"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "# Check number of dimensions for TENSOR\n",
        "TENSOR.ndim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ln9dys5VTGe4"
      },
      "source": [
        "Tensor memiliki ukuran sebesar 3, selanjutnya mengecek bentuk `TENSOR`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hdVv4iNRTGe5",
        "outputId": "1c751000-1cb0-44f4-ae7f-4cb0cfb072bf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 3, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# Check shape of TENSOR\n",
        "TENSOR.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zxk8GU7oTGe5"
      },
      "source": [
        "Output `torch.Size([1, 3, 3])` menunjukkan bahwa tensor tersebut memiliki tiga dimensi dengan panjang masing-masing dimensi adalah 1, 3, dan 3. Dimensinya dari luar ke dalam, hal tersebut menandakan bahwa tensor ini memiliki satu salinan, dan setiap salinan terdiri dari tiga baris dan tiga kolom.\n",
        "\n",
        "\n",
        "![example of different tensor dimensions](https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/00-pytorch-different-tensor-dimensions.png)\n",
        "\n",
        "Setelah melakukan beberapa percobaan pada scalar, vector, matrix dan tensor, kesimpulan yang didapatkan adalah:\n",
        "\n",
        "| Nama | Penjelasan | Jumlah Dimensi | Tanda yang biasa digunakan dalam latihan ini |\n",
        "| ----- | ----- | ----- | ----- |\n",
        "| **scalar** | tensor dengan dimensi nol, yang berarti hanya mengandung satu nilai tunggal | 0 | Lower (`a`) |\n",
        "| **vector** | tensor satu dimensi yang berisi sekumpulan nilai | 1 | Lower (`y`) |\n",
        "| **matrix** | tensor dua dimensi yang terdiri dari baris dan kolom | 2 | Upper (`Q`) |\n",
        "| **tensor** | baris bilangan n-dimensi | dapat berupa bilangan apa saja, tensor 0 dimensi adalah skalar, tensor 1 dimensi adalah vektor | Upper (`X`) |\n",
        "\n",
        "Untuk memudahkan pemahaman mengenai scalar, vector, matrix dan tensor, dapat dilihat pada gambar di bawah ini.\n",
        "\n",
        "![scalar vector matrix tensor and what they look like](https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/00-scalar-vector-matrix-tensor.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dms7G4nkTGe5"
      },
      "source": [
        "### Random tensors\n",
        "\n",
        "\n",
        "Random tensors dalam konteks PyTorch merujuk pada pembuatan tensor dengan nilai-nilai yang dihasilkan secara acak. PyTorch menyediakan fungsi dan modul untuk menghasilkan random tensors dengan berbagai distribusi.\n",
        "\n",
        "Catatan dari materi ini: Kami telah menetapkan bahwa tensor mewakili beberapa bentuk data.\n",
        "\n",
        "Dan model pembelajaran mesin seperti jaringan syaraf tiruan memanipulasi dan mencari pola di dalam tensor.\n",
        "\n",
        "Namun, ketika membangun model pembelajaran mesin dengan PyTorch, jarang sekali Anda membuat tensor dengan tangan (seperti yang kita lakukan).\n",
        "\n",
        "Sebaliknya, model pembelajaran mesin sering kali dimulai dengan tensor angka acak yang besar dan menyesuaikan angka acak ini saat bekerja melalui data untuk merepresentasikannya dengan lebih baik.\n",
        "\n",
        "Intinya:\n",
        "\n",
        "`Mulai dengan angka acak -> lihat data -> perbarui angka acak -> lihat data -> perbarui angka acak...`\n",
        "\n",
        "Sebagai seorang ilmuwan data, Anda dapat menentukan bagaimana model machine learning memulai (inisialisasi), melihat data (representasi), dan memperbarui (optimasi) angka-angka acak.\n",
        "\n",
        "Kita akan membahas langkah-langkah ini nanti.\n",
        "\n",
        "Untuk saat ini, mari kita lihat bagaimana cara membuat tensor bilangan acak.\n",
        "\n",
        "\n",
        "Hal ini dapat dilakukan dengan [`torch.rand()`](https://pytorch.org/docs/stable/generated/torch.rand.html) dan memasukkan parameter `size`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EOJEtDx--GnK",
        "outputId": "21f67cbc-114f-49c5-b2fa-c1c05a271284"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0.1086, 0.5956, 0.0901, 0.5975],\n",
              "         [0.9820, 0.6489, 0.2166, 0.5995],\n",
              "         [0.6719, 0.1667, 0.3120, 0.9764]]),\n",
              " torch.float32)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "# membuat random tensor dengan ukuran (3, 4)\n",
        "random_tensor = torch.rand(size=(3, 4))\n",
        "random_tensor, random_tensor.dtype"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-wB1c_cXTGe5"
      },
      "source": [
        "Fleksibilitas dari `torch.rand()` adalah, kita dapat menyesuaikan ukurannya menjadi apa pun yang kita inginkan.\n",
        "\n",
        "Sebagai contoh, kita menginginkan tensor acak dalam bentuk gambar umum `[224, 224, 3]` (`[height, width, color_channels`])."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xMF_NUp3Ym__",
        "outputId": "fd879708-5913-4ba3-d8f0-d9cb71e6f02f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([224, 224, 3]), 3)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        " # membuat random tensor dengan ukuran (224, 224, 3)\n",
        "random_image_size_tensor = torch.rand(size=(224, 224, 3))\n",
        "random_image_size_tensor.shape, random_image_size_tensor.ndim"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Output yang dihasilkan menjelaskan bahwa tensor ini memiliki tiga dimensi dengan ukuran masing-masing dimensi adalah 224, 224, dan 3. Dimensi pertama dan kedua merepresentasikan tinggi dan lebar citra, sedangkan dimensi ketiga merepresentasikan jumlah channel warna."
      ],
      "metadata": {
        "id": "GN6TGiU-5IWU"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0MQNTY0eTGe6"
      },
      "source": [
        "### Zeros and ones\n",
        "\n",
        "Terkadang kita hanya ingin mengisi tensor dengan nol atau satu.\n",
        "\n",
        "Hal ini sering terjadi pada masking (seperti menutupi beberapa nilai dalam satu tensor dengan nol agar model tidak mempelajarinya).\n",
        "\n",
        "Selanjutnya membuat tensor yang hanya berisi angka nol [`torch.zeros()`](https://pytorch.org/docs/stable/generated/torch.zeros.html)\n",
        "\n",
        "\n",
        "Di sini kita akan menggunakan parameter `size` lagi."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oCzhd0hl9Vp6",
        "outputId": "b6007799-bc1d-46fc-fe0e-8bbfe23572a4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0.]]),\n",
              " torch.float32)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "# Membuat tensor 3x4 dengan isi nol\n",
        "zeros = torch.zeros(size=(3, 4))\n",
        "zeros, zeros.dtype"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Output menghasilkan tensor dengan ukuran 3x4 yang berisi angka nol (zeros)."
      ],
      "metadata": {
        "id": "59YKe1j36Z4w"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDQBZJRUZWTN"
      },
      "source": [
        "Kita juga dapat melakukan hal tersebut dengan hanya mengisi angka 1 (ones) menggunakan [`torch.ones()` ](https://pytorch.org/docs/stable/generated/torch.ones.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HRe6sSXiTGe6",
        "outputId": "1d804117-3255-4c72-96ee-9d9ed4b5a6fe"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[1., 1., 1., 1.],\n",
              "         [1., 1., 1., 1.],\n",
              "         [1., 1., 1., 1.]]),\n",
              " torch.float32)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "# Membuat tensor 3x4 dengan isi satu\n",
        "ones = torch.ones(size=(3, 4))\n",
        "ones, ones.dtype"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tensor yang dihasilkan berisi angka 1 dengan ukuran 3x4"
      ],
      "metadata": {
        "id": "Urtfeas161Jl"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hib1NYrSarL2"
      },
      "source": [
        "### Membuat rentang dan tensor\n",
        "\n",
        "Ketika kita menginginkan rentang angka, seperti 1 hingga 10 atau 0 hingga 100.\n",
        "\n",
        "Jika range yang biasa kita buat di Python menggunakan `range()` kita dapat menggunakan `torch.arange(start, end, step)` untuk melakukannya di tensor.\n",
        "\n",
        "Di mana:\n",
        "* `start` = awal rentang (mis. 0)\n",
        "* `end` = akhir rentang (misalnya 10)\n",
        "* `step` = berapa banyak langkah di antara setiap nilai (misalnya 1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1IqUs81d9W4W",
        "outputId": "698342dc-e74e-4e14-e9cf-961df1d95a71"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-a404776195c1>:2: UserWarning: torch.range is deprecated and will be removed in a future release because its behavior is inconsistent with Python's range builtin. Instead, use torch.arange, which produces values in [start, end).\n",
            "  zero_to_ten_deprecated = torch.range(0, 10) # Note: this may return an error in the future\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "# Use torch.arange(), torch.range() is deprecated\n",
        "zero_to_ten_deprecated = torch.range(0, 10) # Note: this may return an error in the future\n",
        "\n",
        "# Create a range of values 0 to 10\n",
        "zero_to_ten = torch.arange(start=0, end=10, step=1)\n",
        "zero_to_ten"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tensor ini mencakup nilai-nilai integer dari 0 hingga 9, dihasilkan dengan menggunakan fungsi torch.arange() dengan parameter start=0, end=10 (perhatikan bahwa end adalah nilai yang tidak dimasukkan dalam rentang), dan step=1. Hasilnya adalah tensor yang mencakup setiap nilai dalam rentang tersebut."
      ],
      "metadata": {
        "id": "LYBvwHlGo1ZX"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-bXf0Ugbh-D"
      },
      "source": [
        "Sometimes you might want one tensor of a certain type with the same\n",
        "\n",
        "1.   Item daftar\n",
        "2.   Item daftar\n",
        "\n",
        "shape as another tensor.\n",
        "\n",
        "For example, a tensor of all zeros with the same shape as a previous tensor.\n",
        "\n",
        "To do so you can use [`torch.zeros_like(input)`](https://pytorch.org/docs/stable/generated/torch.zeros_like.html) or [`torch.ones_like(input)`](https://pytorch.org/docs/1.9.1/generated/torch.ones_like.html) which return a tensor filled with zeros or ones in the same shape as the `input` respectively."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kita juga dapat melakukan hal yang sama dengan tensor yang hanya berisi angka 0 dengan menggunakan [`torch.zeros_like(input)`](https://pytorch.org/docs/stable/generated/torch.zeros_like.html) atau [`torch.ones_like(input)`](https://pytorch.org/docs/1.9.1/generated/torch.ones_like.html)."
      ],
      "metadata": {
        "id": "ohd0-ahlo97S"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZvXwUut5BhHq",
        "outputId": "0f8a59f3-d5c5-4ffb-8f08-b25fc11920ec"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "# Can also create a tensor of zeros similar to another tensor\n",
        "ten_zeros = torch.zeros_like(input=zero_to_ten) # will have same shape\n",
        "ten_zeros"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Seperti yang dapat dilihat pada output, tensor berisi angka nol (zeros) dengan range 0 sampai 10."
      ],
      "metadata": {
        "id": "rqkxHL9zpjwF"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "huKZ6QlYTGe7"
      },
      "source": [
        "### Tipe Data Tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q3MoGnpw9XaF",
        "outputId": "5f62558f-eb98-46a8-f3ad-1fd0e7b1036a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([3]), torch.float32, device(type='cpu'))"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "# Tipe data default untuk tensor adalah float32\n",
        "float_32_tensor = torch.tensor([3.0, 6.0, 9.0],\n",
        "                               dtype=None, # defaults to None, which is torch.float32 or whatever datatype is passed\n",
        "                               device=None, # defaults to None, which uses the default tensor type\n",
        "                               requires_grad=False) # if True, operations performed on the tensor are recorded\n",
        "\n",
        "float_32_tensor.shape, float_32_tensor.dtype, float_32_tensor.device"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Kode di atas menciptakan tensor dengan tipe data float32 secara eksplisit dan menunjukkan informasi tentang bentuk (shape), tipe data, dan perangkat tempat tensor disimpan, tensor ini adalah 1 dimensi dengan panjang 3, menyimpan nilai-nilai dengan presisi floating-point 32-bit. Tensor ini disimpan di CPU"
      ],
      "metadata": {
        "id": "Os4KoICPvb1d"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MhP8kzDfe_ty"
      },
      "source": [
        "Selain masalah bentuk (bentuk tensor yang tidak sama), dua masalah paling umum lainnya yang akan Anda temui di PyTorch adalah masalah tipe data dan perangkat.\n",
        "\n",
        "Sebagai contoh, salah satu tensor adalah torch.float32 dan yang lainnya adalah torch.float16 (PyTorch sering kali menyukai tensor dengan format yang sama).\n",
        "\n",
        "Atau salah satu tensor Anda ada di CPU dan yang lainnya ada di GPU (PyTorch menyukai kalkulasi antar tensor berada di perangkat yang sama).\n",
        "\n",
        "Kita akan membahas lebih lanjut tentang perangkat ini nanti.\n",
        "\n",
        "Untuk saat ini, mari kita buat sebuah tensor dengan dtype=torch.float16."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PKSuajld_09s",
        "outputId": "b84279b0-b745-44b6-fed3-5b6b426e7158"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float16"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "float_16_tensor = torch.tensor([3.0, 6.0, 9.0],\n",
        "                               dtype=torch.float16) # torch.half would also work\n",
        "\n",
        "float_16_tensor.dtype"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "kode ini menghasilkan tensor dengan nilai float dan tipe data float16, yang berguna dalam situasi di mana hemat memori diperlukan dan kehilangan presisi dapat diterima."
      ],
      "metadata": {
        "id": "9zJTb-Yfx6wL"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gUjkB2AX7Upz"
      },
      "source": [
        "## Mendapatkan Informasi dari Tensor\n",
        "\n",
        "Setelah membuat tensor, kita mungkin ingin mendapatkan beberapa informasi dari tensor.\n",
        "\n",
        "Kita sudah pernah melihat ini sebelumnya, tetapi tiga atribut yang paling umum yang ingin Anda ketahui tentang tensor adalah:\n",
        "* `shape` - bagaimana bentuk tensor tersebut? (beberapa operasi memerlukan aturan bentuk tertentu)\n",
        "* `dtype` - dalam tipe data apa elemen-elemen di dalam tensor disimpan?\n",
        "* `device` - pada perangkat apa tensor disimpan? (biasanya GPU atau CPU)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hd_X4D0j7Umq",
        "outputId": "e1eabc29-940f-409f-cf16-46c8ae7b7351"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.8694, 0.5677, 0.7411, 0.4294],\n",
            "        [0.8854, 0.5739, 0.2666, 0.6274],\n",
            "        [0.2696, 0.4414, 0.2969, 0.8317]])\n",
            "Shape of tensor: torch.Size([3, 4])\n",
            "Datatype of tensor: torch.float32\n",
            "Device tensor is stored on: cpu\n"
          ]
        }
      ],
      "source": [
        "# Buat Tensor\n",
        "some_tensor = torch.rand(3, 4)\n",
        "\n",
        "# Mendapatkan Informasi Detail dari Tensor\n",
        "print(some_tensor)\n",
        "print(f\"Shape of tensor: {some_tensor.shape}\")\n",
        "print(f\"Datatype of tensor: {some_tensor.dtype}\")\n",
        "print(f\"Device tensor is stored on: {some_tensor.device}\") # mengikuti CPU default"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BdiWvoAi7UjL"
      },
      "source": [
        "## Manipulasi Tensor (operasi tensor)\n",
        "\n",
        "In deep learning, data (images, text, video, audio, protein structures, etc) gets represented as tensors.\n",
        "\n",
        "A model learns by investigating those tensors and performing a series of operations (could be 1,000,000s+) on tensors to create a representation of the patterns in the input data.\n",
        "\n",
        "These operations are often a wonderful dance between:\n",
        "* Addition\n",
        "* Substraction\n",
        "* Multiplication (element-wise)\n",
        "* Division\n",
        "* Matrix multiplication\n",
        "\n",
        "And that's it. Sure there are a few more here and there but these are the basic building blocks of neural networks.\n",
        "\n",
        "Stacking these building blocks in the right way, you can create the most sophisticated of neural networks (just like lego!)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sk_6Dd7L7Uce"
      },
      "source": [
        "### Operasi Dasar\n",
        "Let's start with a few of the fundamental operations, addition (`+`), subtraction (`-`), mutliplication (`*`).\n",
        "\n",
        "They work just as you think they would."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X71WpQoPD7a4",
        "outputId": "7ded95d2-ca48-4a63-a7e6-1e041e8d3ddb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([11, 12, 13])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "# Membuat tensor dengan nilai [1, 2, 3]\n",
        "tensor = torch.tensor([1, 2, 3])\n",
        "tensor + 10"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tensor yang memiliki nilai [11, 12, 13], namun nilai ini tidak disimpan secara permanen ke dalam tensor tensor."
      ],
      "metadata": {
        "id": "fbaKnuJKGvEA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sp4TlTWWEFeO",
        "outputId": "dc0d09ee-c84c-47de-9c53-d07d67796d3e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([10, 20, 30])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "# Mengalikan setiap elemen tensor dengan 10\n",
        "tensor * 10"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tensor yang memiliki nilai [10, 20, 30], namun nilai ini juga tidak disimpan secara permanen."
      ],
      "metadata": {
        "id": "iCpRdyZjG036"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XuB1UjCIEJIA",
        "outputId": "7eee954e-09bc-418a-95cf-3ccdcd3aedc2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "# Tidak ada perubahan pada tensor asli tanpa reassign\n",
        "tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tensor tetap memiliki nilai [1, 2, 3], karena operasi sebelumnya tidak diassign kembali ke tensor."
      ],
      "metadata": {
        "id": "N0wwhjosG6Lt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U4iWKoLsENry",
        "outputId": "5a7af838-2670-4219-a4a5-1389bb01160c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-9, -8, -7])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "# Mengurangkan nilai 10 dari setiap elemen tensor dan men-assign kembali\n",
        "tensor = tensor - 10\n",
        "tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tensor sekarang memiliki nilai [-9, -8, -7], karena nilai 10 dikurangkan dari setiap elemen dan diassign kembali ke tensor."
      ],
      "metadata": {
        "id": "f1UZiqo8HALz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tFgZY-PaFNXa",
        "outputId": "ced4c014-ab87-49d9-e0ca-1a0a98c75ddc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "# Menambah nilai 10 ke setiap elemen tensor dan men-assign kembali\n",
        "tensor = tensor + 10\n",
        "tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tensor kembali memiliki nilai [1, 2, 3], karena nilai 10 ditambahkan ke setiap elemen dan diassign kembali ke tensor."
      ],
      "metadata": {
        "id": "R8t80oVfHGDk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uVysdk3kFWbY",
        "outputId": "cb90fce3-7e35-437e-f502-57a01bfe2c5e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([10, 20, 30])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "# Menggunakan fungsi multiply dari torch untuk mengalikan setiap elemen dengan 10\n",
        "torch.multiply(tensor, 10)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tensor dengan nilai [10, 20, 30], namun nilai ini tidak disimpan secara permanen ke dalam tensor."
      ],
      "metadata": {
        "id": "QE5Glwa_HSQV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IxuPJIpNFbqO",
        "outputId": "d90bb4f6-a9db-41a4-ecf0-5179280ba1d5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "# Tensor asli tidak berubah, masih [1, 2, 3]\n",
        "tensor\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tensor tetap memiliki nilai [1, 2, 3], karena operasi sebelumnya tidak mengubah tensor asli."
      ],
      "metadata": {
        "id": "sVARtay8HWR8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S5v3RkR0F2Jq",
        "outputId": "313d35c9-7804-44eb-cab4-f7c8ce997496"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 2, 3]) * tensor([1, 2, 3])\n",
            "Equals: tensor([1, 4, 9])\n"
          ]
        }
      ],
      "source": [
        "# Perkalian elemen-wise (setiap elemen dikali elemen yang setara, indeks 0->0, 1->1, 2->2)\n",
        "print(tensor, \"*\", tensor)\n",
        "print(\"Equals:\", tensor * tensor)\n",
        "tensor([1, 2, 3]) * tensor([1, 2, 3])\n",
        "Equals: tensor([1, 4, 9])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Penjelasan: Operasi perkalian elemen-wise menghasilkan tensor baru yang nilai-nilainya merupakan hasil perkalian setiap elemen pada posisi yang sama."
      ],
      "metadata": {
        "id": "wK8DotMKHb5y"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TT5fVuyu7q5z"
      },
      "source": [
        "### Perkalian Matrix\n",
        "\n",
        "One of the most common operations in machine learning and deep learning algorithms (like neural networks) is [matrix multiplication](https://www.mathsisfun.com/algebra/matrix-multiplying.html).\n",
        "\n",
        "PyTorch implements matrix multiplication functionality in the [`torch.matmul()`](https://pytorch.org/docs/stable/generated/torch.matmul.html) method.\n",
        "\n",
        "The main two rules for matrix multiplication to remember are:\n",
        "\n",
        "1. The **inner dimensions** must match:\n",
        "  * `(3, 2) @ (3, 2)` won't work\n",
        "  * `(2, 3) @ (3, 2)` will work\n",
        "  * `(3, 2) @ (2, 3)` will work\n",
        "2. The resulting matrix has the shape of the **outer dimensions**:\n",
        " * `(2, 3) @ (3, 2)` -> `(2, 2)`\n",
        " * `(3, 2) @ (2, 3)` -> `(3, 3)`\n",
        "\n",
        "> **Note:** \"`@`\" in Python is the symbol for matrix multiplication.\n",
        "\n",
        "> **Resource:** You can see all of the rules for matrix multiplication using `torch.matmul()` [in the PyTorch documentation](https://pytorch.org/docs/stable/generated/torch.matmul.html).\n",
        "\n",
        "Let's create a tensor and perform element-wise multiplication and matrix multiplication on it.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZE7loucmDlEM",
        "outputId": "442b5642-fb38-4b53-d492-0f8a968064ca"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# Membuat tensor dengan nilai [1, 2, 3]\n",
        "tensor = torch.tensor([1, 2, 3])\n",
        "tensor.shape\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "torch.Size([3]), menunjukkan bahwa tensor ini adalah tensor 1 dimensi dengan panjang 3."
      ],
      "metadata": {
        "id": "yVzUT4j5IUlV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i42gkUeHvI_1",
        "outputId": "eb04a8c8-8c86-4841-9dc8-768ecc919e21"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 4, 9])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "# Perkalian elemen-wise pada tensor\n",
        "tensor * tensor\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PvCBiiTTDk8y",
        "outputId": "1bd24f6c-36fb-4834-84e8-33068e79e21a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(14)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "# Perkalian matriks menggunakan torch.matmul\n",
        "torch.matmul(tensor, tensor)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "14, hasil dari perkalian matriks antara tensor dan dirinya sendiri."
      ],
      "metadata": {
        "id": "i5lxnkO1IWNz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4E_pROBDk2r",
        "outputId": "7865a9ee-53a9-4602-e822-33103b44f2d9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(14)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "# Can also use the \"@\" symbol for matrix multiplication, though not recommended\n",
        "tensor @ tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Operasi tensor * tensor menghasilkan perkalian elemen-wise pada tensor, menghasilkan tensor baru dengan nilai [1, 4, 9].\n",
        "torch.matmul(tensor, tensor) menghasilkan perkalian matriks antara tensor dan dirinya sendiri, menghasilkan skalar 14.\n",
        "Penggunaan simbol \"@\" memiliki hasil yang sama dengan torch.matmul, tetapi penggunaan torch.matmul lebih disarankan untuk kejelasan kode."
      ],
      "metadata": {
        "id": "JheWk7DUIXDU"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obbginUMv43A"
      },
      "source": [
        "Kita bisa menggunakan perkalian matrix menggunakan `torch.matmul()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6qMSaLOoJscL",
        "outputId": "28e17529-ca7d-4014-cfc0-4704d3f14c5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 442 µs, sys: 0 ns, total: 442 µs\n",
            "Wall time: 645 µs\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(14)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "%%time\n",
        "# Perkalian matriks secara manual\n",
        "# (hindari melakukan operasi dengan for loop sebisa mungkin, karena mereka mahal secara komputasi)\n",
        "value = 0\n",
        "for i in range(len(tensor)):\n",
        "  value += tensor[i] * tensor[i]\n",
        "value\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVWiKB0KwH74",
        "outputId": "0f3e5b52-d76d-4cec-a55d-9f17e11827a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 78 µs, sys: 0 ns, total: 78 µs\n",
            "Wall time: 82.5 µs\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(14)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "%%time\n",
        "torch.matmul(tensor, tensor)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aJ4DDmo1TGe-"
      },
      "source": [
        "## Error yang biasa terjadi di Deep Learning (shape error)\n",
        "\n",
        "Because much of deep learning is multiplying and performing operations on matrices and matrices have a strict rule about what shapes and sizes can be combined, one of the most common errors you'll run into in deep learning is shape mismatches."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rN5RcoD4Jo6y",
        "outputId": "1f2676b6-33c6-4c27-c975-3c380d296c75"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 23.,  32.],\n",
              "        [ 53.,  74.],\n",
              "        [ 83., 116.]])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "# Shapes need to be in the right way\n",
        "tensor_A = torch.tensor([[1, 2],\n",
        "                         [3, 4],\n",
        "                         [5, 6]], dtype=torch.float32)\n",
        "\n",
        "tensor_B = torch.tensor([[7, 10],\n",
        "                         [8, 11]], dtype=torch.float32)\n",
        "\n",
        "torch.matmul(tensor_A, tensor_B) # (this will error)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bentuk dari tensor_A dan tensor_B tidak dapat dikalikan (3x2 dan 3x2), maka dari itu kita mengubah bentuk dari salah satu tensor, di sini saya mengubah bentuk dari tensor_B menjadi 2x2   "
      ],
      "metadata": {
        "id": "itv-hkexsfbl"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HNA6MZEFxWVt"
      },
      "source": [
        "We can make matrix multiplication work between `tensor_A` and `tensor_B` by making their inner dimensions match.\n",
        "\n",
        "One of the ways to do this is with a **transpose** (switch the dimensions of a given tensor).\n",
        "\n",
        "You can perform transposes in PyTorch using either:\n",
        "* `torch.transpose(input, dim0, dim1)` - where `input` is the desired tensor to transpose and `dim0` and `dim1` are the dimensions to be swapped.\n",
        "* `tensor.T` - where `tensor` is the desired tensor to transpose.\n",
        "\n",
        "Let's try the latter."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUqgaANiy1wq",
        "outputId": "09947825-b6df-43ca-d1a7-6ac209f72f5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 2.],\n",
            "        [3., 4.],\n",
            "        [5., 6.]])\n",
            "tensor([[ 7., 10.],\n",
            "        [ 8., 11.]])\n"
          ]
        }
      ],
      "source": [
        "# Menampilkan tensor_A dan tensor_B\n",
        "print(tensor_A)\n",
        "print(tensor_B)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Menampilkan nilai tensor_A dan tensor_B."
      ],
      "metadata": {
        "id": "RdoaLAr4NZeG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DveqxO7iy_Fi",
        "outputId": "de17abca-c766-4a15-fb17-2128f9c0b839"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 2.],\n",
            "        [3., 4.],\n",
            "        [5., 6.]])\n",
            "tensor([[ 7.,  8.],\n",
            "        [10., 11.]])\n"
          ]
        }
      ],
      "source": [
        "# Menampilkan tensor_A dan transpose dari tensor_B\n",
        "print(tensor_A)\n",
        "print(tensor_B.T)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Menampilkan nilai tensor_A dan transpose dari tensor_B."
      ],
      "metadata": {
        "id": "VUZUtDSJNbZb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35rEIu-NKtVE",
        "outputId": "abcfee67-de1a-477a-924c-534a8d25d4ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original shapes: tensor_A = torch.Size([3, 2]), tensor_B = torch.Size([2, 2])\n",
            "\n",
            "New shapes: tensor_A = torch.Size([3, 2]) (same as above), tensor_B.T = torch.Size([2, 2])\n",
            "\n",
            "Multiplying: torch.Size([3, 2]) * torch.Size([2, 2]) <- inner dimensions match\n",
            "\n",
            "Output:\n",
            "\n",
            "tensor([[ 27.,  30.],\n",
            "        [ 61.,  68.],\n",
            "        [ 95., 106.]])\n",
            "\n",
            "Output shape: torch.Size([3, 2])\n"
          ]
        }
      ],
      "source": [
        "# Operasi perkalian matriks bekerja ketika tensor_B di-transpose\n",
        "print(f\"Original shapes: tensor_A = {tensor_A.shape}, tensor_B = {tensor_B.shape}\\n\")\n",
        "print(f\"New shapes: tensor_A = {tensor_A.shape} (sama seperti sebelumnya), tensor_B.T = {tensor_B.T.shape}\\n\")\n",
        "print(f\"Multiplying: {tensor_A.shape} * {tensor_B.T.shape} <- dimensi dalam cocok\\n\")\n",
        "print(\"Output:\\n\")\n",
        "output = torch.matmul(tensor_A, tensor_B.T)\n",
        "print(output)\n",
        "print(f\"\\nOutput shape: {output.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Menampilkan informasi tentang bentuk asli dan bentuk baru dari tensor_A dan tensor_B.T. Kemudian, melakukan perkalian matriks antara tensor_A dan transpose dari tensor_B, dan menampilkan hasilnya beserta bentuknya."
      ],
      "metadata": {
        "id": "vYUnSvrpNU10"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MfcFEqfLjN24"
      },
      "source": [
        "Kita juga bisa menggunakan [`torch.mm()`](https://pytorch.org/docs/stable/generated/torch.mm.html) versi lebih pendek dari `torch.matmul()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x3rJvW_TTGe_",
        "outputId": "88bf6615-b9ca-4c62-ea53-33841a53eb5e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 27.,  30.],\n",
              "        [ 61.,  68.],\n",
              "        [ 95., 106.]])"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "# torch.mm adalah singkatan dari matmul\n",
        "torch.mm(tensor_A, tensor_B.T)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hasil dari operasi perkalian matriks menggunakan fungsi torch.mm antara tensor_A dan transpose dari tensor_B."
      ],
      "metadata": {
        "id": "C5NCHRX-NQB7"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXKozI4T0hFi"
      },
      "source": [
        "Without the transpose, the rules of matrix mulitplication aren't fulfilled and we get an error like above.\n",
        "\n",
        "How about a visual?\n",
        "\n",
        "![visual demo of matrix multiplication](https://github.com/mrdbourke/pytorch-deep-learning/raw/main/images/00-matrix-multiply-crop.gif)\n",
        "\n",
        "You can create your own matrix multiplication visuals like this at http://matrixmultiplication.xyz/.\n",
        "\n",
        "> **Note:** A matrix multiplication like this is also referred to as the [**dot product**](https://www.mathsisfun.com/algebra/vectors-dot-product.html) of two matrices.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hA64Z4DmkB31"
      },
      "source": [
        "Neural networks are full of matrix multiplications and dot products.\n",
        "\n",
        "The [`torch.nn.Linear()`](https://pytorch.org/docs/1.9.1/generated/torch.nn.Linear.html) module (we'll see this in action later on), also known as a feed-forward layer or fully connected layer, implements a matrix multiplication between an input `x` and a weights matrix `A`.\n",
        "\n",
        "$$\n",
        "y = x\\cdot{A^T} + b\n",
        "$$\n",
        "\n",
        "Where:\n",
        "* `x` is the input to the layer (deep learning is a stack of layers like `torch.nn.Linear()` and others on top of each other).\n",
        "* `A` is the weights matrix created by the layer, this starts out as random numbers that get adjusted as a neural network learns to better represent patterns in the data (notice the \"`T`\", that's because the weights matrix gets transposed).\n",
        "  * **Note:** You might also often see `W` or another letter like `X` used to showcase the weights matrix.\n",
        "* `b` is the bias term used to slightly offset the weights and inputs.\n",
        "* `y` is the output (a manipulation of the input in the hopes to discover patterns in it).\n",
        "\n",
        "This is a linear function (you may have seen something like $y = mx+b$ in high school or elsewhere), and can be used to draw a straight line!\n",
        "\n",
        "Let's play around with a linear layer.\n",
        "\n",
        "Try changing the values of `in_features` and `out_features` below and see what happens.\n",
        "\n",
        "Do you notice anything to do with the shapes?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mC_MjKW1LX7T",
        "outputId": "3b2ea99f-3f53-4701-b6e1-71546fb3c184"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: torch.Size([3, 2])\n",
            "\n",
            "Output:\n",
            "tensor([[2.2368, 1.2292, 0.4714, 0.3864, 0.1309, 0.9838],\n",
            "        [4.4919, 2.1970, 0.4469, 0.5285, 0.3401, 2.4777],\n",
            "        [6.7469, 3.1648, 0.4224, 0.6705, 0.5493, 3.9716]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "\n",
            "Output shape: torch.Size([3, 6])\n"
          ]
        }
      ],
      "source": [
        "# Karena layer linear dimulai dengan matriks berbobot acak, mari membuatnya dapat direproduksi (lebih banyak tentang ini nanti)\n",
        "torch.manual_seed(42)\n",
        "# Ini menggunakan perkalian matriks\n",
        "linear = torch.nn.Linear(in_features=2, # in_features = cocokkan dengan dimensi dalam input\n",
        "                         out_features=6) # out_features = deskripsikan dimensi luar\n",
        "x = tensor_A\n",
        "output = linear(x)\n",
        "print(f\"Input shape: {x.shape}\\n\")\n",
        "print(f\"Output:\\n{output}\\n\\nOutput shape: {output.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Menampilkan bentuk input, hasil output, dan bentuk output dari layer linear."
      ],
      "metadata": {
        "id": "UWezXb1_NIPQ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zIGrP5j1pN7j"
      },
      "source": [
        "> **Question:** What happens if you change `in_features` from 2 to 3 above? Does it error? How could you change the shape of the input (`x`) to accomodate to the error? Hint: what did we have to do to `tensor_B` above?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPNF0nMWoGEj"
      },
      "source": [
        "If you've never done it before, matrix multiplication can be a confusing topic at first.\n",
        "\n",
        "But after you've played around with it a few times and even cracked open a few neural networks, you'll notice it's everywhere.\n",
        "\n",
        "Remember, matrix multiplication is all you need.\n",
        "\n",
        "![matrix multiplication is all you need](https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/00_matrix_multiplication_is_all_you_need.jpeg)\n",
        "\n",
        "*When you start digging into neural network layers and building your own, you'll find matrix multiplications everywhere. **Source:** https://marksaroufim.substack.com/p/working-class-deep-learner*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pjMmrJOOPv5e"
      },
      "source": [
        "### Finding the min, max, mean, sum, etc (aggregation)\n",
        "\n",
        "Now we've seen a few ways to manipulate tensors, let's run through a few ways to aggregate them (go from more values to less values).\n",
        "\n",
        "First we'll create a tensor and then find the max, min, mean and sum of it.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jrFQbe5fP1Rk",
        "outputId": "8fd989fa-4e8d-4102-bd88-058a56f64e08"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90])"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "# Membuat tensor\n",
        "x = torch.arange(0, 100, 10)\n",
        "x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tensor yang dibuat dengan menggunakan fungsi torch.arange dengan parameter start=0, end=100, dan step=10."
      ],
      "metadata": {
        "id": "bxemMGD5NgmC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "torch.arange(0, 100, 10) membuat tensor dengan rentang nilai dari 0 hingga kurang dari 100, dengan langkah 10.\n",
        "Hasilnya adalah tensor dengan nilai [0, 10, 20, 30, 40, 50, 60, 70, 80, 90]."
      ],
      "metadata": {
        "id": "YsEazS3ANjrh"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-J-wfMdlsEco"
      },
      "source": [
        "Mencoba agregasi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5wSP9YKP3Lb",
        "outputId": "cac9bae8-10ce-4383-a25f-0d8aa5bc8f96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Minimum: 0\n",
            "Maximum: 90\n",
            "Mean: 45.0\n",
            "Sum: 450\n"
          ]
        }
      ],
      "source": [
        "print(f\"Minimum: {x.min()}\")\n",
        "print(f\"Maximum: {x.max()}\")\n",
        "# print(f\"Mean: {x.mean()}\") # ini akan error\n",
        "print(f\"Mean: {x.type(torch.float32).mean()}\") # tidak akan berfungsi tanpa tipe data float\n",
        "print(f\"Sum: {x.sum()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Menampilkan nilai minimum, maksimum, rata-rata, dan jumlah dari tensor x"
      ],
      "metadata": {
        "id": "PEzPM8dINm1n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "x.min() mengembalikan nilai minimum dari tensor x.\n",
        "x.max() mengembalikan nilai maksimum dari tensor x.\n",
        "x.mean() akan menghasilkan error karena operasi mean memerlukan tipe data float. Oleh karena itu, x.type(torch.float32).mean() digunakan untuk mengubah tipe data tensor menjadi float sebelum menghitung rata-rata.\n",
        "x.sum() mengembalikan jumlah dari semua elemen dalam tensor x."
      ],
      "metadata": {
        "id": "GMXo1YTONquA"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHoKpsg3sKQE"
      },
      "source": [
        "> **Note:** You may find some methods such as `torch.mean()` require tensors to be in `torch.float32` (the most common) or another specific datatype, otherwise the operation will fail.\n",
        "\n",
        "You can also do the same as above with `torch` methods."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Cr23Y9uP3HO",
        "outputId": "e4c0b805-b36a-48b5-dca4-70257421b4eb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(90), tensor(0), tensor(45.), tensor(450))"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "torch.max(x), torch.min(x), torch.mean(x.type(torch.float32)), torch.sum(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tuple yang berisi nilai maksimum, nilai minimum, rata-rata (dengan tipe data float32), dan jumlah dari tensor x."
      ],
      "metadata": {
        "id": "v6-KAsT_Nweu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "torch.max(x) mengembalikan nilai maksimum dari tensor x.\n",
        "torch.min(x) mengembalikan nilai minimum dari tensor x.\n",
        "torch.mean(x.type(torch.float32)) mengembalikan rata-rata dari tensor x setelah diubah tipe datanya menjadi float32.\n",
        "torch.sum(x) mengembalikan jumlah dari semua elemen dalam tensor x."
      ],
      "metadata": {
        "id": "7-YGbubRN0kY"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7ApCaZjDkvp"
      },
      "source": [
        "### Positional min/max\n",
        "\n",
        "You can also find the index of a tensor where the max or minimum occurs with [`torch.argmax()`](https://pytorch.org/docs/stable/generated/torch.argmax.html) and [`torch.argmin()`](https://pytorch.org/docs/stable/generated/torch.argmin.html) respectively.\n",
        "\n",
        "This is helpful incase you just want the position where the highest (or lowest) value is and not the actual value itself (we'll see this in a later section when using the [softmax activation function](https://pytorch.org/docs/stable/generated/torch.nn.Softmax.html))."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FzNBl9JSGlHi",
        "outputId": "7be593b0-364b-40f0-be93-4c395576638e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor: tensor([10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
            "Index where max value occurs: 8\n",
            "Index where min value occurs: 0\n"
          ]
        }
      ],
      "source": [
        "# Membuat tensor\n",
        "tensor = torch.arange(10, 100, 10)\n",
        "print(f\"Tensor: {tensor}\")\n",
        "\n",
        "# Mengembalikan indeks dari nilai maksimum dan minimum\n",
        "print(f\"Indeks di mana nilai maksimum terjadi: {tensor.argmax()}\")\n",
        "print(f\"Indeks di mana nilai minimum terjadi: {tensor.argmin()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Menampilkan tensor yang dibuat dan indeks dari nilai maksimum dan minimum dalam tensor."
      ],
      "metadata": {
        "id": "4R9fmZ0yN4-L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "torch.arange(10, 100, 10) membuat tensor dengan rentang nilai dari 10 hingga kurang dari 100, dengan langkah 10. Hasilnya adalah tensor dengan nilai [10, 20, 30, 40, 50, 60, 70, 80, 90].\n",
        "tensor.argmax() mengembalikan indeks di mana nilai maksimum dalam tensor terjadi.\n",
        "tensor.argmin() mengembalikan indeks di mana nilai minimum dalam tensor terjadi."
      ],
      "metadata": {
        "id": "04kA4CtpN7Hw"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBu33WihOXBk"
      },
      "source": [
        "### Change tensor datatype\n",
        "\n",
        "As mentioned, a common issue with deep learning operations is having your tensors in different datatypes.\n",
        "\n",
        "If one tensor is in `torch.float64` and another is in `torch.float32`, you might run into some errors.\n",
        "\n",
        "But there's a fix.\n",
        "\n",
        "You can change the datatypes of tensors using [`torch.Tensor.type(dtype=None)`](https://pytorch.org/docs/stable/generated/torch.Tensor.type.html) where the `dtype` parameter is the datatype you'd like to use.\n",
        "\n",
        "First we'll create a tensor and check it's datatype (the default is `torch.float32`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rY2FEsCAOaLu",
        "outputId": "5345c761-7b02-4b74-a108-44335ce2c3d7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.float32"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "# Membuat tensor dan memeriksa tipe datanya\n",
        "tensor = torch.arange(10., 100., 10.)\n",
        "tensor.dtype\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Menampilkan tipe data dari tensor yang dibuat"
      ],
      "metadata": {
        "id": "9FBXC7gXOATH"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jR30FHEc92of"
      },
      "source": [
        "Now we'll create another tensor the same as before but change its datatype to `torch.float16`.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cac8gRYjOeab",
        "outputId": "8fc68e0c-93f1-494b-d0dc-596d62b6eff4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([10., 20., 30., 40., 50., 60., 70., 80., 90.], dtype=torch.float16)"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "source": [
        "# Membuat tensor dengan tipe data float16\n",
        "tensor_float16 = tensor.type(torch.float16)\n",
        "tensor_float16\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Menampilkan tensor yang dibuat dengan tipe data float16"
      ],
      "metadata": {
        "id": "rOOvChL_OHJA"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndVlKJZ4-7_5"
      },
      "source": [
        "And we can do something similar to make a `torch.int8` tensor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Yqovld2Oj6s",
        "outputId": "8a1c3ce7-c29b-4921-a578-7cd6747c59f5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([10, 20, 30, 40, 50, 60, 70, 80, 90], dtype=torch.int8)"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ],
      "source": [
        "# Membuat tensor dengan tipe data int8\n",
        "tensor_int8 = tensor.type(torch.int8)\n",
        "tensor_int8\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Menampilkan tensor yang dibuat dengan tipe data int8."
      ],
      "metadata": {
        "id": "uwuWLq3vOMCj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "tensor.type(torch.int8) mengubah tipe data tensor menjadi int8.\n",
        "tensor_int8 adalah tensor hasil konversi dengan tipe data int8. Perlu dicatat bahwa penggunaan int8 dapat menyebabkan overflow atau underflow tergantung pada nilai-nilai dalam tensor."
      ],
      "metadata": {
        "id": "0uKXlsghOOZE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# > **Note:** Different datatypes can be confusing to begin with. But think of it like this, the lower the number (e.g. 32, 16, 8), the less precise a computer stores the value. And with a lower amount of storage, this generally results in faster computation and a smaller overall model. Mobile-based neural networks often operate with 8-bit integers, smaller and faster to run but less accurate than their float32 counterparts. For more on this, I'd read up about [precision in computing](https://en.wikipedia.org/wiki/Precision_(computer_science)).\n",
        "\n",
        "> **Exercise:** So far we've covered a fair few tensor methods but there's a bunch more in the [`torch.Tensor` documentation](https://pytorch.org/docs/stable/tensors.html), I'd recommend spending 10-minutes scrolling through and looking into any that catch your eye. Click on them and then write them out in code yourself to see what happens."
      ],
      "metadata": {
        "id": "0DiAYARcOT3y"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7CkCtAYmGsHY"
      },
      "source": [
        "### Reshaping, stacking, squeezing and unsqueezing\n",
        "\n",
        "Often times you'll want to reshape or change the dimensions of your tensors without actually changing the values inside them.\n",
        "\n",
        "To do so, some popular methods are:\n",
        "\n",
        "| Method | One-line description |\n",
        "| ----- | ----- |\n",
        "| [`torch.reshape(input, shape)`](https://pytorch.org/docs/stable/generated/torch.reshape.html#torch.reshape) | Reshapes `input` to `shape` (if compatible), can also use `torch.Tensor.reshape()`. |\n",
        "| [`Tensor.view(shape)`](https://pytorch.org/docs/stable/generated/torch.Tensor.view.html) | Returns a view of the original tensor in a different `shape` but shares the same data as the original tensor. |\n",
        "| [`torch.stack(tensors, dim=0)`](https://pytorch.org/docs/1.9.1/generated/torch.stack.html) | Concatenates a sequence of `tensors` along a new dimension (`dim`), all `tensors` must be same size. |\n",
        "| [`torch.squeeze(input)`](https://pytorch.org/docs/stable/generated/torch.squeeze.html) | Squeezes `input` to remove all the dimenions with value `1`. |\n",
        "| [`torch.unsqueeze(input, dim)`](https://pytorch.org/docs/1.9.1/generated/torch.unsqueeze.html) | Returns `input` with a dimension value of `1` added at `dim`. |\n",
        "| [`torch.permute(input, dims)`](https://pytorch.org/docs/stable/generated/torch.permute.html) | Returns a *view* of the original `input` with its dimensions permuted (rearranged) to `dims`. |\n",
        "\n",
        "Why do any of these?\n",
        "\n",
        "Because deep learning models (neural networks) are all about manipulating tensors in some way. And because of the rules of matrix multiplication, if you've got shape mismatches, you'll run into errors. These methods help you make sure the right elements of your tensors are mixing with the right elements of other tensors.\n",
        "\n",
        "Let's try them out.\n",
        "\n",
        "First, we'll create a tensor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EYjRTLOzG4Ev",
        "outputId": "d7126447-6342-4e15-dc97-ce1c8ad59bd5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([1., 2., 3., 4., 5., 6., 7.]), torch.Size([7]))"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "# Membuat tensor\n",
        "import torch\n",
        "x = torch.arange(1., 8.)\n",
        "x, x.shape\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Menampilkan tensor yang dibuat dan bentuknya.\n",
        "\n",
        "\n",
        "torch.arange(1., 8.) membuat tensor dengan rentang nilai dari 1 hingga kurang dari 8, dengan langkah default 1, dan menggunakan tipe data float.\n",
        "x adalah tensor yang dibuat.\n",
        "x.shape mengembalikan bentuk dari tensor x. Dalam hal ini, bentuknya adalah (7,), menunjukkan bahwa ini adalah tensor satu dimensi dengan panjang 7."
      ],
      "metadata": {
        "id": "-SL9S_b2OemH"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_VarMO9CoT8"
      },
      "source": [
        "Now let's add an extra dimension with `torch.reshape()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "US4WjpQ3SG-8",
        "outputId": "bdd9d558-2eea-43d7-ba49-e0aa8e2b13cf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[1., 2., 3., 4., 5., 6., 7.]]), torch.Size([1, 7]))"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "source": [
        "# Menambah dimensi tambahan\n",
        "x_reshaped = x.reshape(1, 7)\n",
        "x_reshaped, x_reshaped.shape\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Menampilkan tensor yang telah ditambahkan dimensi tambahan dan bentuknya.\n",
        "\n",
        "x.reshape(1, 7) mengubah bentuk tensor x menjadi (1, 7), menambahkan dimensi tambahan di sepanjang dimensi pertama.\n",
        "x_reshaped adalah tensor yang telah mengalami reshaping.\n",
        "x_reshaped.shape mengembalikan bentuk dari tensor x_reshaped, yang sekarang adalah (1, 7)."
      ],
      "metadata": {
        "id": "jJgLk8f6Oowt"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tig5xm0jCxuU"
      },
      "source": [
        "We can also change the view with `torch.view()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WDN2BNe5TGfB",
        "outputId": "072a03cf-546c-49a5-ae3b-e571f7f1c0ff"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[1., 2., 3., 4., 5., 6., 7.]]), torch.Size([1, 7]))"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ],
      "source": [
        "# Mengubah tampilan (memiliki data yang sama dengan aslinya tetapi mengubah tampilan)\n",
        "# Lihat lebih lanjut: https://stackoverflow.com/a/54507446/7900723\n",
        "z = x.view(1, 7)\n",
        "z, z.shape\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Menampilkan tensor yang telah mengalami perubahan tampilan dan bentuknya.\n",
        "\n",
        "Penjelasan:\n",
        "\n",
        "x.view(1, 7) mengubah tampilan tensor x menjadi (1, 7), tetapi mempertahankan data yang sama seperti aslinya.\n",
        "z adalah tensor yang telah mengalami perubahan tampilan.\n",
        "z.shape mengembalikan bentuk dari tensor z, yang sekarang adalah (1, 7). Perhatikan bahwa ini mempertahankan jumlah elemen yang sama dengan tensor asli, hanya mengubah cara tensor diorganisir dalam memori."
      ],
      "metadata": {
        "id": "TgZN8Jp7O26h"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m8joAaUEC2NX"
      },
      "source": [
        "Remember though, changing the view of a tensor with `torch.view()` really only creates a new view of the *same* tensor.\n",
        "\n",
        "So changing the view changes the original tensor too."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2DxURVvXTGfC",
        "outputId": "daf59dae-4c80-41a8-fc64-3193c097afcb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[5., 2., 3., 4., 5., 6., 7.]]), tensor([5., 2., 3., 4., 5., 6., 7.]))"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ],
      "source": [
        "# Mengubah z mengubah x\n",
        "z[:, 0] = 5\n",
        "z, x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Menampilkan tensor z setelah diubah, dan menunjukkan bahwa perubahan di tensor z juga mempengaruhi tensor x.\n",
        "\n",
        "Penjelasan:\n",
        "\n",
        "Memodifikasi elemen pertama dari kolom pertama tensor z dengan z[:, 0] = 5 mengakibatkan perubahan nilai tersebut.\n",
        "Karena z dan x berbagi data yang sama setelah operasi view, perubahan yang dilakukan di tensor z juga tercermin di tensor x. Hal ini menunjukkan bahwa keduanya menggunakan memori yang sama, dan perubahan di salah satu tensor akan mempengaruhi tensor lainnya."
      ],
      "metadata": {
        "id": "rpoBauPCO9iq"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YxnqDBlpDDJ_"
      },
      "source": [
        "If we wanted to stack our new tensor on top of itself five times, we could do so with `torch.stack()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pX5Adf3ORiTK",
        "outputId": "b0d8bcd0-d2f5-49b2-f57f-0155ff78d237"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[5., 2., 3., 4., 5., 6., 7.],\n",
              "        [5., 2., 3., 4., 5., 6., 7.],\n",
              "        [5., 2., 3., 4., 5., 6., 7.],\n",
              "        [5., 2., 3., 4., 5., 6., 7.]])"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ],
      "source": [
        "# Menumpuk tensor satu di atas yang lain\n",
        "x_stacked = torch.stack([x, x, x, x], dim=0) # coba ubah dim menjadi dim=1 dan lihat apa yang terjadi\n",
        "x_stacked\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Menampilkan tensor yang telah ditumpuk secara vertikal (berdasarkan dimensi 0) dari tensor x.\n",
        "\n",
        "Penjelasan:\n",
        "\n",
        "torch.stack([x, x, x, x], dim=0) melakukan penumpukan vertikal dari tensor-tensor dalam list.\n",
        "Hasilnya adalah tensor dengan dimensi baru (4, 7), di mana 4 adalah jumlah tensor yang ditumpuk dan 7 adalah panjang tensor x.\n",
        "Jika dim diubah menjadi dim=1, maka penumpukan akan dilakukan secara horizontal, dan dimensi baru menjadi (1, 28)."
      ],
      "metadata": {
        "id": "IlXUWEhfPDd4"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ET56QzNHDuOI"
      },
      "source": [
        "How about removing all single dimensions from a tensor?\n",
        "\n",
        "To do so you can use `torch.squeeze()` (I remember this as *squeezing* the tensor to only have dimensions over 1)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w2Y2HEoDRxJZ",
        "outputId": "d44e0f7c-b946-4040-8049-dcce475ec4a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Previous tensor: tensor([[5., 2., 3., 4., 5., 6., 7.]])\n",
            "Previous shape: torch.Size([1, 7])\n",
            "\n",
            "New tensor: tensor([5., 2., 3., 4., 5., 6., 7.])\n",
            "New shape: torch.Size([7])\n"
          ]
        }
      ],
      "source": [
        "# Menampilkan tensor dan bentuk sebelumnya\n",
        "print(f\"Previous tensor: {x_reshaped}\")\n",
        "print(f\"Previous shape: {x_reshaped.shape}\")\n",
        "\n",
        "# Menghapus dimensi tambahan dari x_reshaped\n",
        "x_squeezed = x_reshaped.squeeze()\n",
        "print(f\"\\nNew tensor: {x_squeezed}\")\n",
        "print(f\"New shape: {x_squeezed.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Menampilkan tensor sebelum dan setelah dimensi tambahan dihapus, serta bentuk masing-masing.\n",
        "\n",
        "Penjelasan:\n",
        "\n",
        "x_reshaped adalah tensor dengan dimensi (1, 7) setelah dimensi tambahan ditambahkan sebelumnya.\n",
        "x_reshaped.squeeze() menghapus dimensi tambahan, sehingga tensor menjadi (7,).\n",
        "Hasilnya adalah tensor baru x_squeezed dan bentuk baru yang mencerminkan perubahan tersebut.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "lu3qi6w0PMMI"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "acjDLk8WD8NC"
      },
      "source": [
        "And to do the reverse of `torch.squeeze()` you can use `torch.unsqueeze()` to add a dimension value of 1 at a specific index."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CUC-DEEwSYv7",
        "outputId": "675ff209-6acc-45f2-f06e-b38c5dacd9dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Previous tensor: tensor([5., 2., 3., 4., 5., 6., 7.])\n",
            "Previous shape: torch.Size([7])\n",
            "\n",
            "New tensor: tensor([[5., 2., 3., 4., 5., 6., 7.]])\n",
            "New shape: torch.Size([1, 7])\n"
          ]
        }
      ],
      "source": [
        "print(f\"Previous tensor: {x_squeezed}\")\n",
        "print(f\"Previous shape: {x_squeezed.shape}\")\n",
        "\n",
        "# Menambah dimensi tambahan dengan unsqueeze\n",
        "x_unsqueezed = x_squeezed.unsqueeze(dim=0)\n",
        "print(f\"\\nNew tensor: {x_unsqueezed}\")\n",
        "print(f\"New shape: {x_unsqueezed.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R9DuJzXgFbM5"
      },
      "source": [
        "Menampilkan tensor sebelum dan setelah dimensi tambahan ditambahkan kembali menggunakan unsqueeze, serta bentuk masing-masing.\n",
        "\n",
        "Penjelasan:\n",
        "\n",
        "x_squeezed adalah tensor dengan dimensi (7,) setelah dimensi tambahan dihapus sebelumnya.\n",
        "x_squeezed.unsqueeze(dim=0) menambahkan dimensi tambahan di posisi pertama, sehingga tensor menjadi (1, 7).\n",
        "Hasilnya adalah tensor baru x_unsqueezed dan bentuk baru yang mencerminkan perubahan tersebut.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fCRGCX8DTGfC",
        "outputId": "04e480c0-b547-4bcc-e2fc-f51e6db62292"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Previous shape: torch.Size([224, 224, 3])\n",
            "New shape: torch.Size([3, 224, 224])\n"
          ]
        }
      ],
      "source": [
        "# Membuat tensor dengan bentuk tertentu\n",
        "x_original = torch.rand(size=(224, 224, 3))\n",
        "\n",
        "# Mengubah urutan sumbu dengan permute pada tensor asli\n",
        "x_permuted = x_original.permute(2, 0, 1) # menggeser sumbu 0->1, 1->2, 2->0\n",
        "\n",
        "print(f\"Previous shape: {x_original.shape}\")\n",
        "print(f\"New shape: {x_permuted.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Menampilkan bentuk tensor sebelum dan setelah diubah menggunakan permute.\n",
        "\n",
        "Penjelasan:\n",
        "\n",
        "torch.rand(size=(224, 224, 3)) membuat tensor dengan bentuk (224, 224, 3) dan nilai acak.\n",
        "x_original.permute(2, 0, 1) mengubah urutan sumbu tensor, sehingga sumbu 0 pindah ke posisi 1, sumbu 1 pindah ke posisi 2, dan sumbu 2 pindah ke posisi 0.\n",
        "Hasilnya adalah tensor baru x_permuted dengan bentuk yang diubah.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "X6L9SEQZPity"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06LKaFemGBoE"
      },
      "source": [
        "> **Note**: Because permuting returns a *view* (shares the same data as the original), the values in the permuted tensor will be the same as the original tensor and if you change the values in the view, it will change the values of the original."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nEPqVL7fTGfC"
      },
      "source": [
        "## Indexing (selecting data from tensors)\n",
        "\n",
        "Sometimes you'll want to select specific data from tensors (for example, only the first column or second row).\n",
        "\n",
        "To do so, you can use indexing.\n",
        "\n",
        "If you've ever done indexing on Python lists or NumPy arrays, indexing in PyTorch with tensors is very similar."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oSXzdxCQTGfD",
        "outputId": "b21eb584-1ba0-4a93-b249-57e804208bd8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[1, 2, 3],\n",
              "          [4, 5, 6],\n",
              "          [7, 8, 9]]]),\n",
              " torch.Size([1, 3, 3]))"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ],
      "source": [
        "# Membuat tensor\n",
        "import torch\n",
        "x = torch.arange(1, 10).reshape(1, 3, 3)\n",
        "x, x.shape\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Menampilkan tensor yang dibuat dan bentuknya.\n",
        "\n",
        "Penjelasan:\n",
        "\n",
        "torch.arange(1, 10) membuat tensor dengan rentang nilai dari 1 hingga kurang dari 10.\n",
        ".reshape(1, 3, 3) mengubah bentuk tensor menjadi (1, 3, 3), menambahkan dimensi tambahan.\n",
        "x adalah tensor yang dibuat.\n",
        "x.shape mengembalikan bentuk dari tensor x, yang sekarang adalah (1, 3, 3).\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "BFu59WG5PpJa"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQG5krnKG43B"
      },
      "source": [
        "Indexing values goes outer dimension -> inner dimension (check out the square brackets)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zv_Z3IAzTGfD",
        "outputId": "9f39f47c-97c9-426b-b2ec-d240b3f033e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First square bracket:\n",
            "tensor([[1, 2, 3],\n",
            "        [4, 5, 6],\n",
            "        [7, 8, 9]])\n",
            "Second square bracket: tensor([1, 2, 3])\n",
            "Third square bracket: 1\n"
          ]
        }
      ],
      "source": [
        "# Mari melakukan indexing berdasarkan kurung siku\n",
        "print(f\"First square bracket:\\n{x[0]}\")\n",
        "print(f\"Second square bracket: {x[0][0]}\")\n",
        "print(f\"Third square bracket: {x[0][0][0]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Menampilkan hasil indexing dari tensor menggunakan kurung siku.\n",
        "\n",
        "Penjelasan:\n",
        "\n",
        "x[0] mengambil elemen pada indeks 0 dari dimensi pertama tensor x, menghasilkan tensor dengan bentuk (3, 3).\n",
        "x[0][0] mengambil elemen pada indeks 0 dari dimensi kedua tensor sebelumnya, menghasilkan tensor dengan bentuk (3,).\n",
        "x[0][0][0] mengambil elemen pada indeks 0 dari dimensi ketiga tensor sebelumnya, menghasilkan nilai tunggal."
      ],
      "metadata": {
        "id": "a5RdsoSqP219"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XaLjaIFxHe89"
      },
      "source": [
        "You can also use `:` to specify \"all values in this dimension\" and then use a comma (`,`) to add another dimension."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gCT09pqeTGfD",
        "outputId": "2c9d0b81-8d34-4a59-f938-5026561d08d1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 2, 3]])"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ],
      "source": [
        "# Mengambil semua nilai dimensi ke-0 dan indeks ke-0 dari dimensi ke-1\n",
        "x[:, 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dwDx_gMsTGfD",
        "outputId": "698d593d-ceb8-4f43-87f5-64accd8aa3c1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2, 5, 8]])"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ],
      "source": [
        "# Mengambil semua nilai dimensi ke-0 dan ke-1 tetapi hanya indeks ke-1 dari dimensi ke-2\n",
        "x[:, :, 1]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xiw3_1E3TGfD",
        "outputId": "11d5b0f8-dc7d-458a-9eaa-1f0dd766206d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([5])"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ],
      "source": [
        "# Mengambil semua nilai dimensi ke-0 tetapi hanya nilai indeks ke-1 dari dimensi ke-1 dan ke-2\n",
        "x[:, 1, 1]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XFVEgrKhTGfD",
        "outputId": "a0ed4c9c-03b3-4542-e370-c7dd257a971d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ],
      "source": [
        "# Mengambil indeks ke-0 dari dimensi ke-0 dan ke-1 serta semua nilai dari dimensi ke-2\n",
        "x[0, 0, :] # sama dengan x[0][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Menampilkan hasil indexing dari tensor x dengan menggunakan indeks tertentu.\n",
        "\n",
        "Penjelasan:\n",
        "\n",
        "x[:, 0] mengambil semua nilai dari dimensi ke-0 dan indeks ke-0 dari dimensi ke-1, menghasilkan tensor dengan bentuk (3,).\n",
        "x[:, :, 1] mengambil semua nilai dari dimensi ke-0 dan ke-1, tetapi hanya indeks ke-1 dari dimensi ke-2, menghasilkan tensor dengan bentuk (1, 3).\n",
        "x[:, 1, 1] mengambil semua nilai dari dimensi ke-0, tetapi hanya nilai indeks ke-1 dari dimensi ke-1 dan ke-2, menghasilkan nilai tunggal.\n",
        "x[0, 0, :] atau x[0][0] mengambil nilai pada indeks ke-0 dari dimensi ke-0 dan ke-1, serta semua nilai dari dimensi ke-2, menghasilkan tensor dengan bentuk (3,).\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "I85RHNLdQHy_"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Ik0r11RIxtm"
      },
      "source": [
        "Indexing can be quite confusing to begin with, especially with larger tensors (I still have to try indexing multiple times to get it right). But with a bit of practice and following the data explorer's motto (***visualize, visualize, visualize***), you'll start to get the hang of it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h8ZaW0Bq7rCm"
      },
      "source": [
        "## PyTorch tensors & NumPy\n",
        "\n",
        "Since NumPy is a popular Python numerical computing library, PyTorch has functionality to interact with it nicely.  \n",
        "\n",
        "The two main methods you'll want to use for NumPy to PyTorch (and back again) are:\n",
        "* [`torch.from_numpy(ndarray)`](https://pytorch.org/docs/stable/generated/torch.from_numpy.html) - NumPy array -> PyTorch tensor.\n",
        "* [`torch.Tensor.numpy()`](https://pytorch.org/docs/stable/generated/torch.Tensor.numpy.html) - PyTorch tensor -> NumPy array.\n",
        "\n",
        "Let's try them out."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yDrDCnvY7rKS",
        "outputId": "fe24aff2-c10d-4196-8173-b2ad9b02f74d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([1., 2., 3., 4., 5., 6., 7.]),\n",
              " tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64))"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ],
      "source": [
        "# NumPy array ke tensor\n",
        "import torch\n",
        "import numpy as np\n",
        "array = np.arange(1.0, 8.0)\n",
        "tensor = torch.from_numpy(array)\n",
        "array, tensor\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Menampilkan array NumPy dan tensor yang dihasilkan dari konversi.\n",
        "\n",
        "Penjelasan:\n",
        "\n",
        "np.arange(1.0, 8.0) membuat array NumPy dengan rentang nilai dari 1.0 hingga kurang dari 8.0.\n",
        "torch.from_numpy(array) mengonversi array NumPy menjadi tensor PyTorch.\n",
        "array adalah array NumPy yang dibuat.\n",
        "tensor adalah tensor hasil konversi dari array NumPy.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "YNIli5EBQPGL"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16JG6cONLPnO"
      },
      "source": [
        "> **Note:** By default, NumPy arrays are created with the datatype `float64` and if you convert it to a PyTorch tensor, it'll keep the same datatype (as above).\n",
        ">\n",
        "> However, many PyTorch calculations default to using `float32`.\n",
        ">\n",
        "> So if you want to convert your NumPy array (float64) -> PyTorch tensor (float64) -> PyTorch tensor (float32), you can use `tensor = torch.from_numpy(array).type(torch.float32)`.\n",
        "\n",
        "Because we reassigned `tensor` above, if you change the tensor, the array stays the same."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ovwl7VCREv8L",
        "outputId": "29e43330-05f8-4208-db16-0ca24d2d03aa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([2., 3., 4., 5., 6., 7., 8.]),\n",
              " tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64))"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ],
      "source": [
        "# Mengubah array, tetap mempertahankan tensor\n",
        "array = array + 1\n",
        "array, tensor\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Menampilkan array NumPy setelah diubah dan tensor yang tetap tidak berubah.\n",
        "\n",
        "Penjelasan:\n",
        "\n",
        "Setelah array NumPy diubah dengan operasi array = array + 1, tensor yang telah dibuat dari array sebelumnya tetap tidak berubah.\n",
        "Ini menunjukkan bahwa tensor dan array yang berasal dari torch.from_numpy membagi memori yang sama dan perubahan di satu akan tercermin di yang lain.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vHgiOU3-Qb1w"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "geVvu1p0MTWc"
      },
      "source": [
        "And if you want to go from PyTorch tensor to NumPy array, you can call `tensor.numpy()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xw_7ZyVaTKxQ",
        "outputId": "a482fb7b-5268-43b2-f3fb-02c6f933fa24"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([1., 1., 1., 1., 1., 1., 1.]),\n",
              " array([1., 1., 1., 1., 1., 1., 1.], dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ],
      "source": [
        "# Tensor ke array NumPy\n",
        "tensor = torch.ones(7) # membuat tensor dengan nilai satu dengan tipe data float32\n",
        "numpy_tensor = tensor.numpy() # akan memiliki tipe data float32 kecuali diubah\n",
        "tensor, numpy_tensor\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Menampilkan tensor dan array NumPy yang dihasilkan dari konversi.\n",
        "\n",
        "Penjelasan:\n",
        "\n",
        "torch.ones(7) membuat tensor PyTorch dengan tujuh elemen yang memiliki nilai satu.\n",
        "tensor.numpy() mengonversi tensor PyTorch menjadi array NumPy.\n",
        "tensor adalah tensor yang dibuat.\n",
        "numpy_tensor adalah array NumPy yang dihasilkan dari konversi tensor. Perlu dicatat bahwa perubahan di tensor juga akan tercermin di array NumPy karena keduanya berbagi memori yang sama.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0xjFzSPxQfUY"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dt8yEV1jMfi2"
      },
      "source": [
        "And the same rule applies as above, if you change the original `tensor`, the new `numpy_tensor` stays the same."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mMp6ZSkET4_Y",
        "outputId": "5740e443-2c02-4d6d-9f0b-1ee513c0a4f6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([2., 2., 2., 2., 2., 2., 2.]),\n",
              " array([1., 1., 1., 1., 1., 1., 1.], dtype=float32))"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ],
      "source": [
        "# Mengubah tensor, tetap mempertahankan array\n",
        "tensor = tensor + 1\n",
        "tensor, numpy_tensor\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Menampilkan tensor setelah diubah dan array NumPy yang tetap tidak berubah.\n",
        "\n",
        "Penjelasan:\n",
        "\n",
        "Setelah tensor diubah dengan operasi tensor = tensor + 1, array NumPy yang berasal dari tensor sebelumnya tetap tidak berubah.\n",
        "Ini menunjukkan bahwa tensor dan array yang berasal dari konversi numpy() tidak membagi memori yang sama, dan perubahan di satu tidak memengaruhi yang lain.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "3Tgs2PXjQlFH"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gU3ubCrUkI-"
      },
      "source": [
        "## Reproducibility (trying to take the random out of random)\n",
        "\n",
        "As you learn more about neural networks and machine learning, you'll start to discover how much randomness plays a part.\n",
        "\n",
        "Well, pseudorandomness that is. Because after all, as they're designed, a computer is fundamentally deterministic (each step is predictable) so the randomness they create are simulated randomness (though there is debate on this too, but since I'm not a computer scientist, I'll let you find out more yourself).\n",
        "\n",
        "How does this relate to neural networks and deep learning then?\n",
        "\n",
        "We've discussed neural networks start with random numbers to describe patterns in data (these numbers are poor descriptions) and try to improve those random numbers using tensor operations (and a few other things we haven't discussed yet) to better describe patterns in data.\n",
        "\n",
        "In short:\n",
        "\n",
        "``start with random numbers -> tensor operations -> try to make better (again and again and again)``\n",
        "\n",
        "Although randomness is nice and powerful, sometimes you'd like there to be a little less randomness.\n",
        "\n",
        "Why?\n",
        "\n",
        "So you can perform repeatable experiments.\n",
        "\n",
        "For example, you create an algorithm capable of achieving X performance.\n",
        "\n",
        "And then your friend tries it out to verify you're not crazy.\n",
        "\n",
        "How could they do such a thing?\n",
        "\n",
        "That's where **reproducibility** comes in.\n",
        "\n",
        "In other words, can you get the same (or very similar) results on your computer running the same code as I get on mine?\n",
        "\n",
        "Let's see a brief example of reproducibility in PyTorch.\n",
        "\n",
        "We'll start by creating two random tensors, since they're random, you'd expect them to be different right?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eSwxnwEbTGfF",
        "outputId": "18759416-757c-41f2-d24c-0a8f40ccab13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor A:\n",
            "tensor([[0.8016, 0.3649, 0.6286, 0.9663],\n",
            "        [0.7687, 0.4566, 0.5745, 0.9200],\n",
            "        [0.3230, 0.8613, 0.0919, 0.3102]])\n",
            "\n",
            "Tensor B:\n",
            "tensor([[0.9536, 0.6002, 0.0351, 0.6826],\n",
            "        [0.3743, 0.5220, 0.1336, 0.9666],\n",
            "        [0.9754, 0.8474, 0.8988, 0.1105]])\n",
            "\n",
            "Does Tensor A equal Tensor B? (anywhere)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[False, False, False, False],\n",
              "        [False, False, False, False],\n",
              "        [False, False, False, False]])"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# Membuat dua tensor acak\n",
        "random_tensor_A = torch.rand(3, 4)\n",
        "random_tensor_B = torch.rand(3, 4)\n",
        "\n",
        "print(f\"Tensor A:\\n{random_tensor_A}\\n\")\n",
        "print(f\"Tensor B:\\n{random_tensor_B}\\n\")\n",
        "print(f\"Apakah Tensor A sama dengan Tensor B? (di mana saja)\")\n",
        "random_tensor_A == random_tensor_B\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Menampilkan kedua tensor acak dan hasil perbandingan element-wise apakah Tensor A sama dengan Tensor B.\n",
        "\n",
        "Penjelasan:\n",
        "\n",
        "torch.rand(3, 4) membuat tensor acak dengan bentuk (3, 4).\n",
        "random_tensor_A == random_tensor_B melakukan perbandingan element-wise antara dua tensor. Hasilnya adalah tensor boolean yang menunjukkan apakah elemen pada posisi yang sesuai dalam kedua tensor sama atau tidak.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "V9RgP4H2QsZN"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nPU6mDKJnr8M"
      },
      "source": [
        "Just as you might've expected, the tensors come out with different values.\n",
        "\n",
        "But what if you wanted to created two random tensors with the *same* values.\n",
        "\n",
        "As in, the tensors would still contain random values but they would be of the same flavour.\n",
        "\n",
        "That's where [`torch.manual_seed(seed)`](https://pytorch.org/docs/stable/generated/torch.manual_seed.html) comes in, where `seed` is an integer (like `42` but it could be anything) that flavours the randomness.\n",
        "\n",
        "Let's try it out by creating some more *flavoured* random tensors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sB6d1GfYTGfF",
        "outputId": "367fcc00-219e-4ea2-f07c-56fcc93e589b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor C:\n",
            "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
            "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
            "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
            "\n",
            "Tensor D:\n",
            "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
            "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
            "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
            "\n",
            "Does Tensor C equal Tensor D? (anywhere)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[True, True, True, True],\n",
              "        [True, True, True, True],\n",
              "        [True, True, True, True]])"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ],
      "source": [
        "import torch\n",
        "import random\n",
        "\n",
        "# # Set the random seed\n",
        "RANDOM_SEED=42 # coba ubah ini menjadi nilai yang berbeda dan lihat apa yang terjadi pada angka di bawah\n",
        "torch.manual_seed(seed=RANDOM_SEED)\n",
        "random_tensor_C = torch.rand(3, 4)\n",
        "\n",
        "# Harus mereset seed setiap kali rand() baru dipanggil\n",
        "# Tanpa ini, tensor_D akan berbeda dengan tensor_C\n",
        "torch.random.manual_seed(seed=RANDOM_SEED) # coba komentari baris ini dan lihat apa yang terjadi\n",
        "random_tensor_D = torch.rand(3, 4)\n",
        "\n",
        "print(f\"Tensor C:\\n{random_tensor_C}\\n\")\n",
        "print(f\"Tensor D:\\n{random_tensor_D}\\n\")\n",
        "print(f\"Apakah Tensor C sama dengan Tensor D? (di mana saja)\")\n",
        "random_tensor_C == random_tensor_D\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Menampilkan kedua tensor acak yang dihasilkan dengan seed yang ditetapkan, dan hasil perbandingan element-wise apakah Tensor C sama dengan Tensor D.\n",
        "\n",
        "Penjelasan:\n",
        "\n",
        "torch.manual_seed(seed=RANDOM_SEED) menetapkan seed untuk generator angka acak PyTorch.\n",
        "torch.random.manual_seed(seed=RANDOM_SEED) menetapkan seed untuk generator angka acak PyTorch versi baru, yang digunakan oleh fungsi torch.rand().\n",
        "Mengatur seed memastikan bahwa angka acak yang dihasilkan pada dua tensor tersebut akan sama jika seed-nya sama. Jika seed tidak diatur, nilai tensor_C dan tensor_D mungkin berbeda.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "UnNDXyb2QzcV"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uct53Xr5QRC_"
      },
      "source": [
        "Nice!\n",
        "\n",
        "It looks like setting the seed worked.\n",
        "\n",
        "> **Resource:** What we've just covered only scratches the surface of reproducibility in PyTorch. For more, on reproducbility in general and random seeds, I'd checkout:\n",
        "> * [The PyTorch reproducibility documentation](https://pytorch.org/docs/stable/notes/randomness.html) (a good exericse would be to read through this for 10-minutes and even if you don't understand it now, being aware of it is important).\n",
        "> * [The Wikipedia random seed page](https://en.wikipedia.org/wiki/Random_seed) (this'll give a good overview of random seeds and pseudorandomness in general)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxIIM7t27rQ-"
      },
      "source": [
        "## Running tensors on GPUs (and making faster computations)\n",
        "\n",
        "Deep learning algorithms require a lot of numerical operations.\n",
        "\n",
        "And by default these operations are often done on a CPU (computer processing unit).\n",
        "\n",
        "However, there's another common piece of hardware called a GPU (graphics processing unit), which is often much faster at performing the specific types of operations neural networks need (matrix multiplications) than CPUs.\n",
        "\n",
        "Your computer might have one.\n",
        "\n",
        "If so, you should look to use it whenever you can to train neural networks because chances are it'll speed up the training time dramatically.\n",
        "\n",
        "There are a few ways to first get access to a GPU and secondly get PyTorch to use the GPU.\n",
        "\n",
        "> **Note:** When I reference \"GPU\" throughout this course, I'm referencing a [Nvidia GPU with CUDA](https://developer.nvidia.com/cuda-gpus) enabled (CUDA is a computing platform and API that helps allow GPUs be used for general purpose computing & not just graphics) unless otherwise specified.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0UiR6QpoYQH_"
      },
      "source": [
        "\n",
        "### 1. Getting a GPU\n",
        "\n",
        "You may already know what's going on when I say GPU. But if not, there are a few ways to get access to one.\n",
        "\n",
        "| **Method** | **Difficulty to setup** | **Pros** | **Cons** | **How to setup** |\n",
        "| ----- | ----- | ----- | ----- | ----- |\n",
        "| Google Colab | Easy | Free to use, almost zero setup required, can share work with others as easy as a link | Doesn't save your data outputs, limited compute, subject to timeouts | [Follow the Google Colab Guide](https://colab.research.google.com/notebooks/gpu.ipynb) |\n",
        "| Use your own | Medium | Run everything locally on your own machine | GPUs aren't free, require upfront cost | Follow the [PyTorch installation guidelines](https://pytorch.org/get-started/locally/) |\n",
        "| Cloud computing (AWS, GCP, Azure) | Medium-Hard | Small upfront cost, access to almost infinite compute | Can get expensive if running continually, takes some time to setup right | Follow the [PyTorch installation guidelines](https://pytorch.org/get-started/cloud-partners/) |\n",
        "\n",
        "There are more options for using GPUs but the above three will suffice for now.\n",
        "\n",
        "Personally, I use a combination of Google Colab and my own personal computer for small scale experiments (and creating this course) and go to cloud resources when I need more compute power.\n",
        "\n",
        "> **Resource:** If you're looking to purchase a GPU of your own but not sure what to get, [Tim Dettmers has an excellent guide](https://timdettmers.com/2020/09/07/which-gpu-for-deep-learning/).\n",
        "\n",
        "To check if you've got access to a Nvidia GPU, you can run `!nvidia-smi` where the `!` (also called bang) means \"run this on the command line\".\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vEMcO-9zYc-w",
        "outputId": "04edb72c-0720-428f-e331-1a5908851e67"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: nvidia-smi: command not found\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvkB9p5zYf8E"
      },
      "source": [
        "If you don't have a Nvidia GPU accessible, the above will output something like:\n",
        "\n",
        "```\n",
        "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n",
        "```\n",
        "\n",
        "In that case, go back up and follow the install steps.\n",
        "\n",
        "If you do have a GPU, the line above will output something like:\n",
        "\n",
        "```\n",
        "Wed Jan 19 22:09:08 2022       \n",
        "+-----------------------------------------------------------------------------+\n",
        "| NVIDIA-SMI 495.46       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
        "|-------------------------------+----------------------+----------------------+\n",
        "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
        "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
        "|                               |                      |               MIG M. |\n",
        "|===============================+======================+======================|\n",
        "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
        "| N/A   35C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
        "|                               |                      |                  N/A |\n",
        "+-------------------------------+----------------------+----------------------+\n",
        "                                                                               \n",
        "+-----------------------------------------------------------------------------+\n",
        "| Processes:                                                                  |\n",
        "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
        "|        ID   ID                                                   Usage      |\n",
        "|=============================================================================|\n",
        "|  No running processes found                                                 |\n",
        "+-----------------------------------------------------------------------------+\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UvibZ6e0YcDk"
      },
      "source": [
        "\n",
        "\n",
        "### 2. Getting PyTorch to run on the GPU\n",
        "\n",
        "Once you've got a GPU ready to access, the next step is getting PyTorch to use for storing data (tensors) and computing on data (performing operations on tensors).\n",
        "\n",
        "To do so, you can use the [`torch.cuda`](https://pytorch.org/docs/stable/cuda.html) package.\n",
        "\n",
        "Rather than talk about it, let's try it out.\n",
        "\n",
        "You can test if PyTorch has access to a GPU using [`torch.cuda.is_available()`](https://pytorch.org/docs/stable/generated/torch.cuda.is_available.html#torch.cuda.is_available).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OweDLgwjEvZ2",
        "outputId": "e082466c-9ee6-432d-a159-a86f6c561d4b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ],
      "source": [
        "# Check for GPU\n",
        "import torch\n",
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "menggunakan modul torch untuk memeriksa ketersediaan GPU. Fungsi torch.cuda.is_available() mengembalikan nilai True jika GPU tersedia dan False jika tidak."
      ],
      "metadata": {
        "id": "C7fkcTs9RS1g"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jedZcx2PZFpL"
      },
      "source": [
        "If the above outputs `True`, PyTorch can see and use the GPU, if it outputs `False`, it can't see the GPU and in that case, you'll have to go back through the installation steps.\n",
        "\n",
        "Now, let's say you wanted to setup your code so it ran on CPU *or* the GPU if it was available.\n",
        "\n",
        "That way, if you or someone decides to run your code, it'll work regardless of the computing device they're using.\n",
        "\n",
        "Let's create a `device` variable to store what kind of device is available."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "j92HBCKB7rYa",
        "outputId": "30420ec7-4ec2-41f1-ef6d-47b2052db064"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cpu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 77
        }
      ],
      "source": [
        "# Set device type\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "mengatur variabel device berdasarkan ketersediaan GPU. Jika GPU tersedia, maka nilai device akan diatur menjadi \"cuda\" (mengindikasikan penggunaan GPU). Jika tidak, nilai device akan diatur menjadi \"cpu\" (mengindikasikan penggunaan CPU).\n",
        "\n"
      ],
      "metadata": {
        "id": "P6xIEaOdRWVA"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FjFyPP2WaCch"
      },
      "source": [
        "If the above output `\"cuda\"` it means we can set all of our PyTorch code to use the available CUDA device (a GPU) and if it output `\"cpu\"`, our PyTorch code will stick with the CPU.\n",
        "\n",
        "> **Note:** In PyTorch, it's best practice to write [**device agnostic code**](https://pytorch.org/docs/master/notes/cuda.html#device-agnostic-code). This means code that'll run on CPU (always available) or GPU (if available).\n",
        "\n",
        "If you want to do faster computing you can use a GPU but if you want to do *much* faster computing, you can use multiple GPUs.\n",
        "\n",
        "You can count the number of GPUs PyTorch has access to using [`torch.cuda.device_count()`](https://pytorch.org/docs/stable/generated/torch.cuda.device_count.html#torch.cuda.device_count)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MArsn0DFTGfG",
        "outputId": "efb9fa15-d1cf-4649-bd84-edc1a50ee8e7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ],
      "source": [
        "# Count number of devices\n",
        "torch.cuda.device_count()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fungsi torch.cuda.device_count() digunakan untuk menghitung jumlah GPU yang tersedia pada sistem. Nilai yang dikembalikan akan menunjukkan berapa banyak GPU yang terpasang dan dapat diakses menggunakan PyTorch.\n",
        "\n"
      ],
      "metadata": {
        "id": "Y2KcGe1JReCk"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xVNf1hiqa-gO"
      },
      "source": [
        "Knowing the number of GPUs PyTorch has access to is helpful incase you wanted to run a specific process on one GPU and another process on another (PyTorch also has features to let you run a process across *all* GPUs)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XqQLcuj68OA-"
      },
      "source": [
        "### 3. Putting tensors (and models) on the GPU\n",
        "\n",
        "You can put tensors (and models, we'll see this later) on a specific device by calling [`to(device)`](https://pytorch.org/docs/stable/generated/torch.Tensor.to.html) on them. Where `device` is the target device you'd like the tensor (or model) to go to.\n",
        "\n",
        "Why do this?\n",
        "\n",
        "GPUs offer far faster numerical computing than CPUs do and if a GPU isn't available, because of our **device agnostic code** (see above), it'll run on the CPU.\n",
        "\n",
        "> **Note:** Putting a tensor on GPU using `to(device)` (e.g. `some_tensor.to(device)`) returns a copy of that tensor, e.g. the same tensor will be on CPU and GPU. To overwrite tensors, reassign them:\n",
        ">\n",
        "> `some_tensor = some_tensor.to(device)`\n",
        "\n",
        "Let's try creating a tensor and putting it on the GPU (if it's available)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FhI3srFXEHfP",
        "outputId": "b6364652-0cf7-4785-f152-b7a1c4702a6e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 2, 3]) cpu\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ],
      "source": [
        "# Membuat tensor (default di CPU)\n",
        "tensor = torch.tensor([1, 2, 3])\n",
        "\n",
        "# Tensor tidak berada di GPU\n",
        "print(tensor, tensor.device)\n",
        "\n",
        "# Memindahkan tensor ke GPU (jika tersedia)\n",
        "tensor_on_gpu = tensor.to(device)\n",
        "tensor_on_gpu\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "mencantumkan tensor awal di CPU dan tensor setelah dipindahkan ke GPU (jika GPU tersedia). Jika GPU tidak tersedia, tensor tetap berada di CPU."
      ],
      "metadata": {
        "id": "Gx7fUuCsRqrK"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DxXeRKO0TGfG"
      },
      "source": [
        "If you have a GPU available, the above code will output something like:\n",
        "\n",
        "```\n",
        "tensor([1, 2, 3]) cpu\n",
        "tensor([1, 2, 3], device='cuda:0')\n",
        "```\n",
        "\n",
        "Notice the second tensor has `device='cuda:0'`, this means it's stored on the 0th GPU available (GPUs are 0 indexed, if two GPUs were available, they'd be `'cuda:0'` and `'cuda:1'` respectively, up to `'cuda:n'`).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4puyUX4Bci5D"
      },
      "source": [
        "### 4. Moving tensors back to the CPU\n",
        "\n",
        "What if we wanted to move the tensor back to CPU?\n",
        "\n",
        "For example, you'll want to do this if you want to interact with your tensors with NumPy (NumPy does not leverage the GPU).\n",
        "\n",
        "Let's try using the [`torch.Tensor.numpy()`](https://pytorch.org/docs/stable/generated/torch.Tensor.numpy.html) method on our `tensor_on_gpu`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ChSLJgPTGfG",
        "outputId": "551a202c-c35e-4e2e-b4ca-c2b82d516821"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ],
      "source": [
        "# Jika tensor berada di GPU\n",
        "tensor_on_gpu = tensor.to(device)\n",
        "\n",
        "# Mencoba mengonversi tensor di GPU menjadi NumPy (akan menghasilkan kesalahan)\n",
        "tensor_on_gpu.numpy()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "gunakan .detach().cpu().numpy() untuk mengembalikan tensor ke CPU terlebih dahulu dan kemudian mengonversinya menjadi array NumPy.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-fdekFdLR5dD"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LhymtkRDTGfG"
      },
      "source": [
        "Instead, to get a tensor back to CPU and usable with NumPy we can use [`Tensor.cpu()`](https://pytorch.org/docs/stable/generated/torch.Tensor.cpu.html).\n",
        "\n",
        "This copies the tensor to CPU memory so it's usable with CPUs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gN15s-NdTGfG",
        "outputId": "7f2673ff-5e87-4cd3-edcf-0dad47332b8c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ],
      "source": [
        "# Mengembalikan tensor dari GPU ke CPU dan mengonversinya menjadi NumPy array\n",
        "tensor_back_on_cpu = tensor_on_gpu.cpu().numpy()\n",
        "tensor_back_on_cpu\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dengan menggunakan .cpu().numpy(), Anda memindahkan tensor dari GPU ke CPU dan kemudian mengonversinya menjadi array NumPy. Hal ini memungkinkan operasi ini dilakukan dengan benar tanpa menghasilkan kesalahan.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7zKqerJXR9OU"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qyzNH5lrTGfH"
      },
      "source": [
        "The above returns a copy of the GPU tensor in CPU memory so the original tensor is still on GPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S5u83PCRTGfH",
        "outputId": "18ed4c15-f5a9-48b7-ce0d-7c40d30b8e69"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 2, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ],
      "source": [
        "tensor_on_gpu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xlmBpnuPTGfH"
      },
      "source": [
        "## Exercises\n",
        "\n",
        "All of the exercises are focused on practicing the code above.\n",
        "\n",
        "You should be able to complete them by referencing each section or by following the resource(s) linked.\n",
        "\n",
        "**Resources:**\n",
        "\n",
        "* [Exercise template notebook for 00](https://github.com/mrdbourke/pytorch-deep-learning/blob/main/extras/exercises/00_pytorch_fundamentals_exercises.ipynb).\n",
        "* [Example solutions notebook for 00](https://github.com/mrdbourke/pytorch-deep-learning/blob/main/extras/solutions/00_pytorch_fundamentals_exercise_solutions.ipynb) (try the exercises *before* looking at this).\n",
        "\n",
        "1. Documentation reading - A big part of deep learning (and learning to code in general) is getting familiar with the documentation of a certain framework you're using. We'll be using the PyTorch documentation a lot throughout the rest of this course. So I'd recommend spending 10-minutes reading the following (it's okay if you don't get some things for now, the focus is not yet full understanding, it's awareness). See the documentation on [`torch.Tensor`](https://pytorch.org/docs/stable/tensors.html#torch-tensor) and for [`torch.cuda`](https://pytorch.org/docs/master/notes/cuda.html#cuda-semantics).\n",
        "2. Create a random tensor with shape `(7, 7)`.\n",
        "3. Perform a matrix multiplication on the tensor from 2 with another random tensor with shape `(1, 7)` (hint: you may have to transpose the second tensor).\n",
        "4. Set the random seed to `0` and do exercises 2 & 3 over again.\n",
        "5. Speaking of random seeds, we saw how to set it with `torch.manual_seed()` but is there a GPU equivalent? (hint: you'll need to look into the documentation for `torch.cuda` for this one). If there is, set the GPU random seed to `1234`.\n",
        "6. Create two random tensors of shape `(2, 3)` and send them both to the GPU (you'll need access to a GPU for this). Set `torch.manual_seed(1234)` when creating the tensors (this doesn't have to be the GPU random seed).\n",
        "7. Perform a matrix multiplication on the tensors you created in 6 (again, you may have to adjust the shapes of one of the tensors).\n",
        "8. Find the maximum and minimum values of the output of 7.\n",
        "9. Find the maximum and minimum index values of the output of 7.\n",
        "10. Make a random tensor with shape `(1, 1, 1, 10)` and then create a new tensor with all the `1` dimensions removed to be left with a tensor of shape `(10)`. Set the seed to `7` when you create it and print out the first tensor and it's shape as well as the second tensor and it's shape."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kktrH4yl55jV"
      },
      "source": [
        "## Extra-curriculum\n",
        "\n",
        "* Spend 1-hour going through the [PyTorch basics tutorial](https://pytorch.org/tutorials/beginner/basics/intro.html) (I'd recommend the [Quickstart](https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html) and [Tensors](https://pytorch.org/tutorials/beginner/basics/tensorqs_tutorial.html) sections).\n",
        "* To learn more on how a tensor can represent data, see this video: [What's a tensor?](https://youtu.be/f5liqUk0ZTw)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "interpreter": {
      "hash": "3fbe1355223f7b2ffc113ba3ade6a2b520cadace5d5ec3e828c83ce02eb221bf"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}